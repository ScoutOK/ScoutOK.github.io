module.exports = [
  {
    id: 0,
    name:'Introduction to OpenCV',
    videoUrl:'https://www.youtube.com/embed/oI1GgyRU5a4',
    description:'In this video I talk about computer vision with a specific focus on the OpenCV library. I explain the basics of OpenCV such as the basic data structure and how the library handles object detection. I finish up the presentation by displaying some brief live examples of some basic functions of OpenCV, including face detection, through a web cam.',
    transcript:'Hi, my name is Scout O\'Keefe and today I\'m going to give you a brief introduction into OpenCV. so first off, we need an introduction into what computer vision is. Oh, sorry. OpenCV is an open source computer vision library. So, computer vision it\'s basically any form of computer interaction with a visual input. So, you\'ve all worked with computers for at least several weeks now and you know that computers tend to like data in numbers and images that can be converted to numbers. But our bodies, our eyes, don\'t perceive them as numbers so the computer needs a method to do that. The human visual system can actually do this quite well in most cases and you actually find that humans are very good at pattern recognition. Like babies, early on, can recognize faces can understand the difference. Which I was really fascinated with my niece between the cat between a cat and a dog because, in description, they\'re not that different, but they can understand the difference. It\'s really cool and I find this field particularly interesting because it can give us insight possibly into the complexity of our own brain and visual systems which are which is really cool.\nNow when some people think of computer vision they might picture something like the image on the right which is Terminator vision and while, you know, humanoid robots will probably need computer vision, there are a lot of other applications as well. So here\'s just a few, um. Face recognition and expression recognition like the picture on the top left. Red light traffic cameras like the picture on the top right. Gesture recognition like the bottom right. Optical text recognition like the one in the middle of the bottom which also has a lot of usage is in accessibility ,making documents accessible for people who are low vision are blind. The bottom left, manufacturing just making sure things are lined up computer vision is involved in that. And my favorite example that I found is the middle of the top which is actually tracking the ball during sports and coming up with visualizations out. Because a is a company called Hawkeye does this and actually I was really excited because I\'d seen this watching tennis and I was like “oh my gosh that\'s so cool”. So, they track the ball so then you can show exactly where it landed and be like oh that was a good call by the ref for that oh man mistake.\nSo now we\'ll get into OpenCV, particularly, so as I said before it\'s an open source computer vision and machine learning software library. It\'s bsd open-source license and it\'s free for academic and commercial use. It began as a research project at Intel in 1998 and I think it became public around 2001. It has native interfaces for C++, C, Python, Java, and MATLAB as well as bindings for node. Those are all, however, those are maintained separately so, like, the current version of OpenCV is OpenCV 3 since i was using node i only had access to OpenCV 2.4.7, I believe was what I was using. It has broad OS support, Windows, Mac, Linux, iOS, and Android so you can use on your mobile devices too. It\'s pretty cool. It also contains more than 2,500 optimized algorithms. So as you might guess with a library this large, we\'re not going to get into all of it today just some key points.\nSo we\'re just going to go over the basic data structures of OpenCV, a bit of what it can do, and then some demos that I\'ve built. So, structures. These are the main data structures that are used in OpenCV. A point, it\'s a 2d point, um, has an x and y coordinate so it\'d be like a point on the image. A size is a 2d size structure so it has a width and a height and no location. That\'s what\'s unique about it. And a rectangle is like a size with a location so it\'s fixed on in space. And you actually define a rectangle by defining its lower left-hand corner in this upper right-hand corner. A rotated rectangle is a rectangle that\'s been rotated, I think that\'s somewhat self-explanatory. And, finally, matrix. The matrix is the big one because this is how images are stored and manipulated. So matrices, the primary data structure of OpenCV. I won\'t go into too much depth on this, but it is good to brush up on matrices before using the OpenCV library especially if you\'re going to be using it in one of its more native languages. You’ll note I didn\'t end up using that many that much matrix math on my own and not much linear algebra, but remember matrices means linear algebra so if you don\'t know it I guess brush up on linear algebra before engaging with this library, um. But matrices make a certain amount of sense with images because if you have an image file you have rows and columns of pixels and matrices have rows and columns. So it\'s kind of like you have points, defining in your matrix… matrix defining all of the individual pixels. So the items on your matrix; you have rows which is the height, columns which is the width, channels so if you have a grayscale image you have one channel because it\'s defining the value of white to black; RGB you have three channels red, green, and blue  - And an interesting thing about how OpenCV works is it always wants its colors blue green red, so opposite of what I\'m used to. That was a bit surprising and frustrating at the beginning - and depth and this is you know more hard computer science stuff, how the data is stored.\n OpenCV has a lot of built-in methods to perform basic linear algebraic operations like, excuse me, dot products, cross products, and finding the inverse of a matrix which from my brief learning of linear algebra I remember being a pain trying to find the inverse of larger matrices. So one cool thing that OpenCV can help you do is object detection. So OpenCV uses Viola Jones Haar Cascade for object detection. Viola Jones was developed primarily for the purpose of face detection so there are a lot more cascades for face detection than really anything else. So what a cascade is is it\'s basically a really large HTML that tells you what to look for in an image. The built-in ones for node OpenCV had a bunch of face ones they\'d like for front facing face ones, side face ones, facial features, full human body and then some cars. They had cars and license plates because it\'s, as I said before used, in red light cameras, it\'s good to be able to identify license plates. But you can make cascades for whatever you want. A tutorial i found which seemed like it would take a lot of time because you have to have examples of it - like 40 examples and like 500 negative examples or something - but there was a tutorial for how to make a Haar cascade for a banana which seemed like it might be fun. But so it\'s important in a lot of computer vision tasks like face detection using a controller like if the not the infrared controllers because I think like we uses infrared I think but some controllers is about the camera seeing an object and I think the PlayStation Move does that, although I\'ve only, like, played with it once at the store. So and also gesture recognitions. So it\'s a pattern to check for.\nSo this is just a brief clip of the video at the URL below and this is a demonstration of the Haar cascade. And so you can see it\'s going through and checking the patterns. I mean this doesn\'t really tell you what the patterns it\'s checking for are, but you can see if you can see the faint red line that red box leaves behind that means it\'s found a face. And obviously this is a lot slower than the actual processing speed. The good thing about the cascades is they\'re actually pretty quick compared to other ways to do things and so that\'s why you can, you know, in a camera sometimes have pictures, you know, identify faces in the frame before the picture is even taken. And this is just a small section of a four-minute video if you want to see more of it. \nSo now we\'re going to get into the demo which I thought I had left up here - um okay - and has it crashed? No it hasn\'t! Okay, awesome! It is very buggy. This demo crashes a lot. It\'s, I mean computer vision, is computationally expensive and this is my first stab at it so I don\'t really know how to optimize it yet. So this is an example; this is a built-in function that converts RGB color that\'s coming through my camera into HSV which is hue saturation value. It\'s just a different way of looking at colors which, you know, I have never used this for stuff, but I imagine if you know things were roughly the same shade but very different in in hue or saturation or, you know, value, the third one, um, this might be a way to better detect objects. There\'s also a built in grayscale which just changes it the three channels, it compresses it to one and makes it gray scale. We have contours which it basically looks for contours in the image. And I believe this is just looking for differences in a - great enough difference in shade between nearby pixels. Branching off of contours we have shapes which is it looks for shapes. And you can actually see it breaks sometimes and just shows straight up contours, but for some reason this reminds me of an 80s music video, probably Aha specifically because of the jerky motion. Um and then we have lines which, I like this one, I think it\'s fun but it\'s basically looking for the place where the color changes again and this it\'s taking individual dots and basically making them width one and a line of length 1/50, I think I said 1/50 of the viewscreen for the video. So this might be, you know, as you can see it has a reasonably good edge detection on my shirt, although it also probably thinks all my stripes are edges as well on my shirt. Um so, that\'s just another thing. Now threshold, um, is basically there\'s a value below which everything turns to black a value above which everything turns to white, but this basically my shirt, right now, is a solid black thing. So in terms of if you have a situation where the thing you have is like always going to be darker than than most of its surroundings, or lighter than most of its surroundings, it can help for, you know, object tracking.\nAnd now the big one, um, face detection which I hope works okay. So it\'s a bit screwy it\'s not perfect because these Haar cascades in general are not perfect. So the red circles are supposed to be eyes, the blue circle is face so it\'s pretty good on the face. If I turn to the side it should go away. There is a profile one, um, but I had to build the build this by adding in different Cascades and the more cascades I added in the more likely it was to crash. So I originally had like one for my nose, one for a mouth, one for my profile and it crashed all the time. But, I mean, it\'s easy to see it\'s not perfect occasionally it thinks my mouth is an eye which is pretty typical. Like it\'s a, you know, cause for the eye it looks for like the eyebrow and the darkness underneath. And when I looked for a mouth, it thought every dark thing in the room was a mouth. And right now I have it limited so it will only look for one face and only look for two eyes to hopefully keep down on the computation. That it\'s doing so I\'ll see if i can look at it and make it let\'s see my eyes, but oh it\'s, I can\'t see the screen when I\'m looking at the camera. Um so, I mean, that about wraps it up I just wanted to give a brief introduction and some brief examples and hopefully pique your interest about the field of computer vision.\nThank you.'
  },
  {
    id: 1,
    name:'Motions',
    videoUrl:'https://www.youtube.com/embed/CMZ9WmhWtSc',
    description:'This presentation for Motions was devlivered on Hiring Day which is at the conclusion of the Grace Hopper Program. The resentation was given to gathered recruiters and representatives from external companies participating in Hiring Day. Hiring Day is a joint event with the simultaneous Fullstack Academy cohort.',
  },
  {
    id: 2,
    name: 'Degender Your Internet',
    videoUrl: 'https://www.youtube.com/embed/-bApRMy220w',
    description: 'This Degender Your Internet presentation was given upon the conclusion of a weekend long hackathon as part of the Grace Hopper Program. The version of Degender Your Internet was a minimum viable product used as a base for future work.'
  }
]